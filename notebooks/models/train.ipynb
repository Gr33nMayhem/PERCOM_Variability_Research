{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-12-08T22:23:08.819717Z",
     "end_time": "2023-12-08T22:23:55.835841Z"
    }
   },
   "outputs": [],
   "source": [
    "from experiment import Exp\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "from ptflops import get_model_complexity_info\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-08T22:23:55.838048Z",
     "end_time": "2023-12-08T22:23:55.842056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "# TODO change the path as relative path\n",
    "args.to_save_path = r\"../../data/Run_logs\"\n",
    "args.freq_save_path = r\"../../data/Freq_data\"\n",
    "args.window_save_path = r\"../../data/Sliding_window\"\n",
    "args.root_path = r\"../..\"\n",
    "\n",
    "args.drop_transition = False\n",
    "args.datanorm_type = \"standardization\"  # None ,\"standardization\", \"minmax\"\n",
    "args.filter_scaling_factor = 1\n",
    "args.batch_size = 256\n",
    "args.shuffle = True\n",
    "args.drop_last = False\n",
    "args.train_vali_quote = 0.90\n",
    "# training setting\n",
    "args.train_epochs = 150\n",
    "args.learning_rate = 0.001\n",
    "args.learning_rate_patience = 7\n",
    "args.learning_rate_factor = 0.1\n",
    "args.early_stop_patience = 15\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "args.use_multi_gpu = False\n",
    "\n",
    "args.optimizer = \"Adam\"\n",
    "args.criterion = \"CrossEntropy\"\n",
    "args.seed = 1\n",
    "args.data_name = 'harvar'\n",
    "args.wavelet_filtering = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning = False\n",
    "args.wavelet_filtering_finetuning_percent = 0.5\n",
    "args.wavelet_filtering_learnable = False\n",
    "args.wavelet_filtering_layernorm = False\n",
    "args.regulatization_tradeoff = 0\n",
    "args.number_wavelet_filtering = 12\n",
    "args.difference = False\n",
    "args.filtering = False\n",
    "args.magnitude = False\n",
    "args.weighted_sampler = True\n",
    "args.pos_select = None\n",
    "args.sensor_select = None\n",
    "args.representation_type = \"time\"\n",
    "args.exp_mode = \"LOCV\"\n",
    "\n",
    "config_file = open('../../configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path = os.path.join(args.root_path, config[\"filename\"])\n",
    "args.sampling_freq = config[\"sampling_freq\"]\n",
    "args.num_classes = config[\"num_classes\"]\n",
    "window_seconds = config[\"window_seconds\"]\n",
    "args.windowsize = int(window_seconds * args.sampling_freq)\n",
    "args.input_length = args.windowsize\n",
    "# input information\n",
    "args.c_in = config[\"num_channels\"]\n",
    "args.device = 'bluesense-RWR1'\n",
    "\n",
    "if args.difference:\n",
    "    args.c_in = args.c_in * 2\n",
    "\n",
    "if args.wavelet_filtering:\n",
    "\n",
    "    if args.windowsize % 2 == 1:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize - 1)).floor()) - 2\n",
    "    else:\n",
    "        N_ds = int(torch.log2(torch.tensor(args.windowsize)).floor()) - 2\n",
    "\n",
    "    args.f_in = args.number_wavelet_filtering * N_ds + 1\n",
    "else:\n",
    "    args.f_in = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-08T22:23:55.842056Z",
     "end_time": "2023-12-08T22:23:55.920765Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Use GPU: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the TinyHAR model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Done!\n",
      "INFO:root:Parameter :24864\n",
      "INFO:root:Set the seed as : 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_builder(\n",
      "  24.86 k, 99.992% Params, 1.5 MMac, 100.000% MACs, \n",
      "  (model): TinyHAR_Model(\n",
      "    24.86 k, 99.992% Params, 1.5 MMac, 100.000% MACs, \n",
      "    (layers_conv): ModuleList(\n",
      "      (0): Sequential(\n",
      "        160, 0.644% Params, 66.96 KMac, 4.451% MACs, \n",
      "        (0): Conv2d(120, 0.483% Params, 44.64 KMac, 2.967% MACs, 1, 20, kernel_size=(5, 1), stride=(1, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 7.44 KMac, 0.495% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(40, 0.161% Params, 14.88 KMac, 0.989% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        2.06 k, 8.285% Params, 374.4 KMac, 24.887% MACs, \n",
      "        (0): Conv2d(2.02 k, 8.124% Params, 363.6 KMac, 24.169% MACs, 20, 20, kernel_size=(5, 1), stride=(2, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 3.6 KMac, 0.239% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(40, 0.161% Params, 7.2 KMac, 0.479% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        2.06 k, 8.285% Params, 349.44 KMac, 23.228% MACs, \n",
      "        (0): Conv2d(2.02 k, 8.124% Params, 339.36 KMac, 22.558% MACs, 20, 20, kernel_size=(5, 1), stride=(1, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 3.36 KMac, 0.223% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(40, 0.161% Params, 6.72 KMac, 0.447% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        2.06 k, 8.285% Params, 162.24 KMac, 10.784% MACs, \n",
      "        (0): Conv2d(2.02 k, 8.124% Params, 157.56 KMac, 10.473% MACs, 20, 20, kernel_size=(5, 1), stride=(2, 1))\n",
      "        (1): ReLU(0, 0.000% Params, 1.56 KMac, 0.104% MACs, inplace=True)\n",
      "        (2): BatchNorm2d(40, 0.161% Params, 3.12 KMac, 0.207% MACs, 20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (channel_interaction): SelfAttention_interaction(\n",
      "      1.2 k, 4.826% Params, 93.6 KMac, 6.222% MACs, \n",
      "      (query): Linear(400, 1.609% Params, 31.2 KMac, 2.074% MACs, in_features=20, out_features=20, bias=False)\n",
      "      (key): Linear(400, 1.609% Params, 31.2 KMac, 2.074% MACs, in_features=20, out_features=20, bias=False)\n",
      "      (value): Linear(400, 1.609% Params, 31.2 KMac, 2.074% MACs, in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (channel_fusion): FC(\n",
      "      2.44 k, 9.813% Params, 62.44 KMac, 4.150% MACs, \n",
      "      (fc): Linear(2.44 k, 9.813% Params, 62.44 KMac, 4.150% MACs, in_features=60, out_features=40, bias=True)\n",
      "    )\n",
      "    (activation): ReLU(0, 0.000% Params, 1.04 KMac, 0.069% MACs, )\n",
      "    (temporal_interaction): temporal_LSTM(\n",
      "      13.12 k, 52.767% Params, 351.52 KMac, 23.366% MACs, \n",
      "      (lstm): LSTM(13.12 k, 52.767% Params, 351.52 KMac, 23.366% MACs, 40, 40, batch_first=True)\n",
      "    )\n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.1, inplace=False)\n",
      "    (temporal_fusion): Temporal_Weighted_Aggregation(\n",
      "      1.68 k, 6.757% Params, 42.68 KMac, 2.837% MACs, \n",
      "      (fc_1): Linear(1.64 k, 6.596% Params, 41.64 KMac, 2.768% MACs, in_features=40, out_features=40, bias=True)\n",
      "      (weighs_activation): Tanh(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "      (fc_2): Linear(40, 0.161% Params, 1.04 KMac, 0.069% MACs, in_features=40, out_features=1, bias=False)\n",
      "      (sm): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=1)\n",
      "    )\n",
      "    (prediction): Linear(82, 0.330% Params, 82.0 Mac, 0.005% MACs, in_features=40, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Computational complexity:       1504402.0\n",
      "Number of parameters:           24864   \n",
      " ----------------------- load all the data -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n",
      "----------------------- Get the Sliding Window -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:================ LOCV Mode ====================\n",
      "INFO:root:================ 8 CV ======================\n",
      "INFO:root:================ the 0 th CV Experiment ================ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave one Out Experiment : The 1 Part as the test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:================ Build the model ================ \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Target sampling weights:  [1.95848022e-04 7.50694392e-05]\n",
      "Train data number :  18427\n",
      "The number of classes is :  2\n",
      "The input_length  is :  128\n",
      "The channel_in is :  3\n",
      "Validation data number :  2048\n",
      "Test data number :  14703\n",
      "Build the TinyHAR model!\n",
      "0\n",
      "step time: 12.89126181602478\n",
      "1\n",
      "step time: 0.25542306900024414\n",
      "2\n",
      "step time: 0.10153555870056152\n",
      "3\n",
      "step time: 0.11354207992553711\n",
      "4\n",
      "step time: 0.13305091857910156\n",
      "5\n",
      "step time: 0.17704439163208008\n",
      "6\n",
      "step time: 0.14952611923217773\n",
      "7\n",
      "step time: 0.12153363227844238\n",
      "8\n",
      "step time: 0.17605352401733398\n",
      "9\n",
      "step time: 0.1800532341003418\n",
      "10\n",
      "step time: 0.17003726959228516\n",
      "11\n",
      "step time: 0.1285257339477539\n",
      "12\n",
      "step time: 0.12653446197509766\n",
      "13\n",
      "step time: 0.12553763389587402\n",
      "14\n",
      "step time: 0.11252641677856445\n",
      "15\n",
      "step time: 0.11004376411437988\n",
      "16\n",
      "step time: 0.1530451774597168\n",
      "17\n",
      "step time: 0.12152624130249023\n",
      "18\n",
      "step time: 0.10907220840454102\n",
      "19\n",
      "step time: 0.11252045631408691\n",
      "20\n",
      "step time: 0.1450512409210205\n",
      "21\n",
      "step time: 0.12452578544616699\n",
      "22\n",
      "step time: 0.2290489673614502\n",
      "23\n",
      "step time: 0.13052082061767578\n",
      "24\n",
      "step time: 0.13852548599243164\n",
      "25\n",
      "step time: 0.15804290771484375\n",
      "26\n",
      "step time: 0.13952374458312988\n",
      "27\n",
      "step time: 0.11153221130371094\n",
      "28\n",
      "step time: 0.14704227447509766\n",
      "29\n",
      "step time: 0.10752081871032715\n",
      "30\n",
      "step time: 0.09500741958618164\n",
      "31\n",
      "step time: 0.1275310516357422\n",
      "32\n",
      "step time: 0.18304967880249023\n",
      "33\n",
      "step time: 0.1785287857055664\n",
      "34\n",
      "step time: 0.18704962730407715\n",
      "35\n",
      "step time: 0.16652560234069824\n",
      "36\n",
      "step time: 0.1555335521697998\n",
      "37\n",
      "step time: 0.1135263442993164\n",
      "38\n",
      "step time: 0.16005802154541016\n",
      "39\n",
      "step time: 0.14353156089782715\n",
      "40\n",
      "step time: 0.1930534839630127\n",
      "41\n",
      "step time: 0.20408010482788086\n",
      "42\n",
      "step time: 0.14951825141906738\n",
      "43\n",
      "step time: 0.18804192543029785\n",
      "44\n",
      "step time: 0.20105266571044922\n",
      "45\n",
      "step time: 0.1536252498626709\n",
      "46\n",
      "step time: 0.11452269554138184\n",
      "47\n",
      "step time: 0.14603781700134277\n",
      "48\n",
      "step time: 0.14020943641662598\n",
      "49\n",
      "step time: 0.11652302742004395\n",
      "50\n",
      "step time: 0.11151814460754395\n",
      "51\n",
      "step time: 0.14751958847045898\n",
      "52\n",
      "step time: 0.21304965019226074\n",
      "53\n",
      "step time: 0.20004057884216309\n",
      "54\n",
      "step time: 0.2390456199645996\n",
      "55\n",
      "step time: 0.18103933334350586\n",
      "56\n",
      "step time: 0.2070467472076416\n",
      "57\n",
      "step time: 0.25304412841796875\n",
      "58\n",
      "step time: 0.20104646682739258\n",
      "59\n",
      "step time: 0.23204755783081055\n",
      "60\n",
      "step time: 0.1525416374206543\n",
      "61\n",
      "step time: 0.46208763122558594\n",
      "62\n",
      "step time: 0.23504233360290527\n",
      "63\n",
      "step time: 0.12452387809753418\n",
      "64\n",
      "step time: 0.14752435684204102\n",
      "65\n",
      "step time: 0.1590433120727539\n",
      "66\n",
      "step time: 0.2275559902191162\n",
      "67\n",
      "step time: 0.1990494728088379\n",
      "68\n",
      "step time: 0.10852837562561035\n",
      "69\n",
      "step time: 0.10851120948791504\n",
      "70\n",
      "step time: 0.21005558967590332\n",
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 1 cost time: 39.48067307472229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step time: 0.30110883712768555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Validation for Epoch: 1 cost time: 1.759477138519287\n",
      "INFO:root:VALI: Epoch: 1, Steps: 72 | Train Loss: 0.3095434  Vali Loss: 0.1682325 Vali Accuracy: 0.9384766  Vali weighted F1: 0.9398876  Vali macro F1 0.9277856 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.168232).  Saving model ...\n",
      "0\n",
      "step time: 0.10352587699890137\n",
      "1\n",
      "step time: 0.10303831100463867\n",
      "2\n",
      "step time: 0.20806455612182617\n",
      "3\n",
      "step time: 0.23105669021606445\n",
      "4\n",
      "step time: 0.09752154350280762\n",
      "5\n",
      "step time: 0.18105506896972656\n",
      "6\n",
      "step time: 0.12352871894836426\n",
      "7\n",
      "step time: 0.18204021453857422\n",
      "8\n",
      "step time: 0.08106327056884766\n",
      "9\n",
      "step time: 0.1245276927947998\n",
      "10\n",
      "step time: 0.18804192543029785\n",
      "11\n",
      "step time: 0.16304636001586914\n",
      "12\n",
      "step time: 0.14103913307189941\n",
      "13\n",
      "step time: 0.09400558471679688\n",
      "14\n",
      "step time: 0.2020421028137207\n",
      "15\n",
      "step time: 0.18453121185302734\n",
      "16\n",
      "step time: 0.22655558586120605\n",
      "17\n",
      "step time: 0.08552694320678711\n",
      "18\n",
      "step time: 0.12851810455322266\n",
      "19\n",
      "step time: 0.16203594207763672\n",
      "20\n",
      "step time: 0.11351728439331055\n",
      "21\n",
      "step time: 0.1790330410003662\n",
      "22\n",
      "step time: 0.13691473007202148\n",
      "23\n",
      "step time: 0.28856658935546875\n",
      "24\n",
      "step time: 0.1315147876739502\n",
      "25\n",
      "step time: 0.14652514457702637\n",
      "26\n",
      "step time: 0.17803096771240234\n",
      "27\n",
      "step time: 0.15053844451904297\n",
      "28\n",
      "step time: 0.2240462303161621\n",
      "29\n",
      "step time: 0.16203641891479492\n",
      "30\n",
      "step time: 0.08500385284423828\n",
      "31\n",
      "step time: 0.1275172233581543\n",
      "32\n",
      "step time: 0.32656049728393555\n",
      "33\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{:<30}\u001B[39;00m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{:<8}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mComputational complexity: \u001B[39m\u001B[38;5;124m'\u001B[39m, macs))\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{:<30}\u001B[39;00m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{:<8}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of parameters: \u001B[39m\u001B[38;5;124m'\u001B[39m, params))\n\u001B[1;32m---> 12\u001B[0m \u001B[43mexp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Concordia\\PERCOM_Variability_Model_Research\\experiment.py:342\u001B[0m, in \u001B[0;36mExp.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    339\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[0;32m    341\u001B[0m model_optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 342\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    343\u001B[0m model_optim\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep time: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time))\n",
      "File \u001B[1;32mD:\\Concordia\\Paper 1\\models\\TinyHAR\\ISWC22-HAR\\venv\\Lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Concordia\\Paper 1\\models\\TinyHAR\\ISWC22-HAR\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args.model_type = \"tinyhar\"  #\"deepconvlstm\"#\"sahar\" #\"deepconvlstm\"\n",
    "\n",
    "args.cross_channel_interaction_type = \"attn\"\n",
    "args.cross_channel_aggregation_type = \"FC\"\n",
    "args.temporal_info_interaction_type = \"lstm\"\n",
    "args.temporal_info_aggregation_type = \"tnaive\"\n",
    "exp = Exp(args)\n",
    "macs, params = get_model_complexity_info(exp.model, (1, args.input_length, args.c_in), as_strings=False,\n",
    "                                         print_per_layer_stat=True, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "exp.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-08T19:06:33.639022Z",
     "end_time": "2023-12-08T19:18:57.044705Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args.model_type = \"deepconvlstm\"\n",
    "\n",
    "exp = Exp(args)\n",
    "macs, params = get_model_complexity_info(exp.model, (1, args.input_length, args.c_in), as_strings=False,\n",
    "                                         print_per_layer_stat=True, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "\n",
    "exp.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
